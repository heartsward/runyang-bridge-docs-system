# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æœç´¢APIç«¯ç‚¹
"""
import os
import re
import json
from typing import List, Dict, Any, Optional
from pathlib import Path
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy import or_, and_

from app.core.deps import get_db, get_current_active_user, get_optional_user
from app.models.user import User
from app.models.document import Document, SearchLog
from app.services.search_service import SearchService
import time

router = APIRouter()

@router.get("/documents", summary="æœç´¢æ–‡æ¡£")
async def search_documents(
    q: str = Query(..., description="æœç´¢å…³é”®è¯"),
    doc_type: Optional[str] = Query(None, description="æ–‡æ¡£ç±»å‹è¿‡æ»¤"),
    limit: int = Query(20, description="è¿”å›ç»“æœæ•°é‡é™åˆ¶"),
    offset: int = Query(0, description="ç»“æœåç§»é‡"),
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_optional_user)
):
    """æœç´¢æ–‡æ¡£å†…å®¹"""
    print("=" * 50)
    print("ğŸš€ SEARCH ENDPOINT HIT!")
    print(f"ğŸ” æœç´¢APIè°ƒç”¨: q={q}")
    print("=" * 50)
    start_time = time.time()
    
    try:
        search_service = SearchService()
        
        # æ„å»ºåŸºç¡€æŸ¥è¯¢ - æ‰€æœ‰ç”¨æˆ·éƒ½å¯ä»¥æœç´¢æ‰€æœ‰æ–‡æ¡£
        query = db.query(Document)
        
        # æ–‡æ¡£ç±»å‹è¿‡æ»¤
        if doc_type:
            query = query.filter(Document.file_type == doc_type)
        
        # è·å–æ‰€æœ‰ç›¸å…³æ–‡æ¡£è¿›è¡Œæœç´¢
        documents = query.all()  # æœç´¢æ‰€æœ‰æ–‡æ¡£ä»¥ç¡®ä¿å®Œæ•´æ€§
        print(f"ğŸ” æ‰¾åˆ° {len(documents)} ä¸ªæ–‡æ¡£è¿›è¡Œæœç´¢")
        
        # æœç´¢ç»“æœåˆ†ç±»
        content_results = []     # å†…å®¹åŒ¹é…çš„ç»“æœ
        title_results = []       # ä»…æ ‡é¢˜åŒ¹é…çš„ç»“æœ
        description_results = [] # ä»…æè¿°åŒ¹é…çš„ç»“æœ
        
        for i, doc in enumerate(documents):
            print(f"ğŸ” å¤„ç†ç¬¬ {i+1}/{len(documents)} ä¸ªæ–‡æ¡£: {doc.title}")
            
            content_found = False
            
            # ä¼˜å…ˆæœç´¢æ–‡æ¡£çš„é¢„å¤„ç†å†…å®¹ï¼ˆä¸ç›´æ¥è¯»å–æ–‡ä»¶ï¼‰
            if doc.content_extracted and doc.content:
                print(f"ğŸ” æœç´¢é¢„å¤„ç†å†…å®¹: {doc.title} (å†…å®¹é•¿åº¦: {len(doc.content)})")
                
                try:
                    # åªæœç´¢æ•°æ®åº“ä¸­å·²æå–çš„å†…å®¹
                    matches = search_service.search_in_text(doc.content, q)
                    print(f"ğŸ” æœç´¢ç»“æœ: æ‰¾åˆ° {len(matches) if matches else 0} ä¸ªåŒ¹é…")
                    
                    if matches:
                        content_found = True
                        print(f"ğŸ” å†…å®¹åŒ¹é…æˆåŠŸ: {doc.title} - åŒ¹é…æ•°é‡: {len(matches)}")
                        # è®¡ç®—ç›¸å…³åº¦åˆ†æ•° - å†…å®¹åŒ¹é…ç»™æœ€é«˜åˆ†
                        base_content_score = 0.8  # å†…å®¹åŒ¹é…åŸºç¡€åˆ†æœ€é«˜
                        match_bonus = min(len(matches) / 20.0, 0.15)  # æ ¹æ®åŒ¹é…æ•°é‡ç»™äºˆå¥–åŠ±åˆ†
                        score = min(base_content_score + match_bonus, 1.0)
                        
                        # ç”Ÿæˆé«˜äº®ç‰‡æ®µ
                        highlights = []
                        for match in matches[:3]:  # æ˜¾ç¤ºå‰3ä¸ªåŒ¹é…ç‰‡æ®µ
                            highlights.append({
                                "text": match["text"],
                                "line_number": match["line_number"]
                            })
                        
                        content_results.append({
                            "id": doc.id,
                            "title": doc.title,
                            "description": doc.description,
                            "file_type": doc.file_type,
                            "file_path": doc.file_path,
                            "score": score,
                            "match_count": len(matches),
                            "highlights": highlights,
                            "updated_at": doc.updated_at.isoformat() if doc.updated_at else None,
                            "match_type": "content"  # æ ‡è®°åŒ¹é…ç±»å‹
                        })
                    else:
                        print(f"ğŸ” é¢„å¤„ç†å†…å®¹æ— åŒ¹é…: {doc.title}")
                        
                except Exception as e:
                    print(f"ğŸ” æœç´¢é¢„å¤„ç†å†…å®¹ {doc.id} å¤±è´¥: {str(e)}")
                    print(f"ğŸ” é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {e}")
            else:
                print(f"ğŸ” æ–‡æ¡£æ— é¢„å¤„ç†å†…å®¹: {doc.title} - content_extracted={doc.content_extracted}")
            
            # å¦‚æœå†…å®¹ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œæ£€æŸ¥æ ‡é¢˜å’Œæè¿°
            if not content_found:
                title_match = q.lower() in doc.title.lower()
                description_match = doc.description and q.lower() in doc.description.lower()
                
                if title_match:
                    # æ ‡é¢˜åŒ¹é…åˆ†æ•° - ä½äºå†…å®¹åŒ¹é…
                    base_score = 0.6
                    # å¦‚æœæ ‡é¢˜å¼€å¤´åŒ¹é…ï¼Œåˆ†æ•°æ›´é«˜
                    if doc.title.lower().startswith(q.lower()):
                        score = base_score + 0.15
                    # å¦‚æœæ˜¯å®Œå…¨åŒ¹é…ï¼Œåˆ†æ•°æœ€é«˜
                    elif doc.title.lower() == q.lower():
                        score = base_score + 0.2
                    else:
                        score = base_score
                    
                    # å¯¹æ ‡é¢˜è¿›è¡Œé«˜äº®å¤„ç†
                    import re
                    pattern = re.compile(re.escape(q), re.IGNORECASE)
                    highlighted_title = pattern.sub(lambda m: f"<mark>{m.group()}</mark>", doc.title)
                    highlight_text = f"æ ‡é¢˜: {highlighted_title}"
                    
                    title_results.append({
                        "id": doc.id,
                        "title": doc.title,
                        "description": doc.description,
                        "file_type": doc.file_type,
                        "file_path": doc.file_path,
                        "score": score,
                        "match_count": 1,
                        "highlights": [{"text": highlight_text, "line_number": 1}],
                        "updated_at": doc.updated_at.isoformat() if doc.updated_at else None,
                        "match_type": "title"  # æ ‡è®°åŒ¹é…ç±»å‹
                    })
                
                elif description_match:
                    # æè¿°åŒ¹é…åˆ†æ•° - æœ€ä½ä¼˜å…ˆçº§
                    base_score = 0.4
                    # è®¡ç®—å…³é”®è¯åœ¨æè¿°ä¸­å‡ºç°çš„æ¬¡æ•°
                    match_count = doc.description.lower().count(q.lower())
                    # æ£€æŸ¥æ˜¯å¦åœ¨æè¿°å¼€å¤´å‡ºç°
                    starts_with_keyword = doc.description.lower().startswith(q.lower())
                    
                    # æ ¹æ®åŒ¹é…æ¬¡æ•°å’Œä½ç½®è°ƒæ•´åˆ†æ•°
                    if starts_with_keyword:
                        score = base_score + 0.1
                    elif match_count > 1:
                        score = base_score + 0.05
                    else:
                        score = base_score
                    
                    # å¯¹æè¿°è¿›è¡Œé«˜äº®å¤„ç†
                    import re
                    pattern = re.compile(re.escape(q), re.IGNORECASE)
                    highlighted_desc = pattern.sub(lambda m: f"<mark>{m.group()}</mark>", doc.description)
                    
                    # æˆªå–æè¿°çš„ä¸€éƒ¨åˆ†ä½œä¸ºé«˜äº®æ˜¾ç¤º
                    desc_snippet = doc.description
                    if len(desc_snippet) > 200:
                        # æ‰¾åˆ°å…³é”®è¯é™„è¿‘çš„æ–‡æœ¬
                        match_pos = doc.description.lower().find(q.lower())
                        start = max(0, match_pos - 100)
                        end = min(len(desc_snippet), match_pos + 100)
                        desc_snippet = desc_snippet[start:end]
                        if start > 0:
                            desc_snippet = "..." + desc_snippet
                        if end < len(doc.description):
                            desc_snippet = desc_snippet + "..."
                    
                    highlighted_snippet = pattern.sub(lambda m: f"<mark>{m.group()}</mark>", desc_snippet)
                    highlight_text = f"æè¿°: {highlighted_snippet}"
                    
                    description_results.append({
                        "id": doc.id,
                        "title": doc.title,
                        "description": doc.description,
                        "file_type": doc.file_type,
                        "file_path": doc.file_path,
                        "score": score,
                        "match_count": 1,
                        "highlights": [{"text": highlight_text, "line_number": 1}],
                        "updated_at": doc.updated_at.isoformat() if doc.updated_at else None,
                        "match_type": "description"  # æ ‡è®°åŒ¹é…ç±»å‹
                    })
        
        # åˆå¹¶ç»“æœï¼šå†…å®¹åŒ¹é…ä¼˜å…ˆï¼Œç„¶åæ˜¯æ ‡é¢˜åŒ¹é…ï¼Œæœ€åæ˜¯æè¿°åŒ¹é…
        search_results = content_results + title_results + description_results
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šå†…å®¹ > æ ‡é¢˜ > æè¿°ï¼ŒåŒç±»å‹å†…æŒ‰ç›¸å…³åº¦åˆ†æ•°æ’åº
        def sort_key(result):
            score = result["score"]
            match_type = result["match_type"]
            
            # ç»™ä¸åŒåŒ¹é…ç±»å‹è®¾ç½®æ˜ç¡®çš„ä¼˜å…ˆçº§æƒé‡
            type_priority = {
                "content": 1000,    # å†…å®¹åŒ¹é…ï¼šæƒé‡æœ€é«˜ï¼Œç¡®ä¿å§‹ç»ˆæ’åœ¨å‰é¢
                "title": 500,       # æ ‡é¢˜åŒ¹é…ï¼šä¸­ç­‰æƒé‡
                "description": 100  # æè¿°åŒ¹é…ï¼šæœ€ä½æƒé‡
            }
            
            # ç»¼åˆæ’åºåˆ†æ•° = ç±»å‹ä¼˜å…ˆçº§æƒé‡ + ç›¸å…³åº¦åˆ†æ•°
            # è¿™æ ·å¯ä»¥ç¡®ä¿ç±»å‹ä¼˜å…ˆçº§çš„ç»å¯¹æ€§ï¼ŒåŒæ—¶åœ¨åŒç±»å‹ä¸­æŒ‰ç›¸å…³åº¦æ’åº
            combined_score = type_priority.get(match_type, 0) + score
            
            return combined_score
        
        search_results.sort(key=sort_key, reverse=True)
        
        # åˆ†é¡µ
        total = len(search_results)
        paginated_results = search_results[offset:offset + limit]
        
        # è®°å½•æœç´¢æ—¥å¿—ï¼ˆä»…é™å·²ç™»å½•ç”¨æˆ·ï¼‰
        if current_user:
            response_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            search_log = SearchLog(
                user_id=current_user.id,
                query=q,
                results_count=total,
                response_time=response_time,
                filters={"doc_type": doc_type, "limit": limit, "offset": offset}
            )
            db.add(search_log)
            db.commit()
        
        return {
            "query": q,
            "total": total,
            "limit": limit,
            "offset": offset,
            "results": paginated_results
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")

@router.get("/preview/{document_id}", summary="é¢„è§ˆæ–‡æ¡£å†…å®¹")
async def preview_document(
    document_id: int,
    highlight: Optional[str] = Query(None, description="é«˜äº®å…³é”®è¯"),
    source: Optional[str] = Query("auto", description="å†…å®¹æ¥æº: auto(è‡ªåŠ¨é€‰æ‹©), extracted(é¢„å¤„ç†å†…å®¹), file(åŸå§‹æ–‡ä»¶)"),
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_optional_user)
):
    """é¢„è§ˆæ–‡æ¡£å†…å®¹"""
    try:
        # è·å–æ–‡æ¡£ - æ‰€æœ‰ç”¨æˆ·éƒ½å¯ä»¥é¢„è§ˆæ‰€æœ‰æ–‡æ¡£
        document = db.query(Document).filter(
            Document.id == document_id
        ).first()
        
        if not document:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
        
        content = None
        content_source = "unknown"
        
        # æ ¹æ®sourceå‚æ•°å†³å®šå†…å®¹æ¥æº
        if source == "extracted" or (source == "auto" and document.content_extracted and document.content):
            # ä½¿ç”¨é¢„å¤„ç†çš„å†…å®¹
            if document.content_extracted and document.content:
                content = document.content
                content_source = "extracted"
                print(f"ğŸ” ä½¿ç”¨é¢„å¤„ç†å†…å®¹é¢„è§ˆ: {document.title} (é•¿åº¦: {len(content)})")
            else:
                # å¦‚æœæ²¡æœ‰é¢„å¤„ç†å†…å®¹ä½†è¯·æ±‚é¢„å¤„ç†å†…å®¹ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                if source == "extracted":
                    error_msg = document.content_extraction_error or "å†…å®¹å°šæœªæå–"
                    raise HTTPException(status_code=400, detail=f"é¢„å¤„ç†å†…å®¹ä¸å¯ç”¨: {error_msg}")
        
        # å¦‚æœè¿˜æ²¡æœ‰å†…å®¹ï¼Œå°è¯•ä»æ–‡ä»¶è¯»å–
        if not content:
            if not document.file_path or not os.path.exists(document.file_path):
                raise HTTPException(status_code=400, detail="æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨")
            
            search_service = SearchService()
            content = search_service.extract_file_content(document.file_path)
            content_source = "file"
            print(f"ğŸ” ä½¿ç”¨æ–‡ä»¶ç›´æ¥é¢„è§ˆ: {document.title}")
            
            if not content:
                raise HTTPException(status_code=400, detail="æ— æ³•è¯»å–æ–‡æ¡£å†…å®¹")
        
        # å¦‚æœæœ‰é«˜äº®å…³é”®è¯ï¼Œæ·»åŠ é«˜äº®æ ‡è®°
        if highlight:
            search_service = SearchService()
            content = search_service.highlight_text(content, highlight)
        
        # é™åˆ¶é¢„è§ˆå†…å®¹é•¿åº¦
        original_length = len(content)
        if len(content) > 10000:
            content = content[:10000] + "\n\n... (å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
        
        return {
            "document_id": document_id,
            "title": document.title,
            "file_type": document.file_type,
            "content": content,
            "content_source": content_source,
            "content_extracted": document.content_extracted,
            "content_extraction_error": document.content_extraction_error,
            "original_length": original_length,
            "is_truncated": len(content) < original_length,
            "file_size": os.path.getsize(document.file_path) if document.file_path and os.path.exists(document.file_path) else 0
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é¢„è§ˆå¤±è´¥: {str(e)}")

# èµ„äº§æœç´¢åŠŸèƒ½å·²ç§»é™¤ - æ™ºèƒ½æœç´¢æ¨¡å—ç°åœ¨åªæœç´¢æ–‡æ¡£å†…å®¹

@router.get("/suggestions", summary="è·å–æœç´¢å»ºè®®")
async def get_search_suggestions(
    q: Optional[str] = Query(None, description="éƒ¨åˆ†å…³é”®è¯"),
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_optional_user)
):
    """è·å–æœç´¢å»ºè®®"""
    try:
        suggestions = []
        
        if q and len(q) >= 2:
            # ä»æ–‡æ¡£æ ‡é¢˜ä¸­è·å–å»ºè®®
            doc_titles = db.query(Document.title).filter(
                Document.title.contains(q)
            ).limit(3).all()
            
            for title in doc_titles:
                if title[0] not in suggestions:
                    suggestions.append(title[0])
            
            # ä»æ–‡æ¡£æè¿°ä¸­è·å–å…³é”®è¯å»ºè®®
            docs_with_desc = db.query(Document.description).filter(
                Document.description.isnot(None),
                Document.description.contains(q)
            ).limit(5).all()
            
            # ä»æè¿°ä¸­æå–åŒ…å«æœç´¢è¯çš„çŸ­è¯­
            import re
            for desc_tuple in docs_with_desc:
                desc = desc_tuple[0]
                if desc:
                    # æ‰¾åˆ°åŒ…å«æœç´¢è¯çš„å¥å­ç‰‡æ®µ
                    sentences = re.split(r'[ï¼Œã€‚ã€ï¼›]', desc)
                    for sentence in sentences:
                        if q.lower() in sentence.lower() and len(sentence.strip()) > 0:
                            # æå–å…³é”®çŸ­è¯­ï¼ˆå»æ‰è¿‡é•¿çš„å¥å­ï¼‰
                            if len(sentence.strip()) <= 50:
                                clean_sentence = sentence.strip()
                                if clean_sentence not in suggestions and len(suggestions) < 8:
                                    suggestions.append(clean_sentence)
            
            # èµ„äº§æœç´¢å»ºè®®å·²ç§»é™¤ - åªæä¾›æ–‡æ¡£ç›¸å…³å»ºè®®
        else:
            # è¿”å›çƒ­é—¨æœç´¢å»ºè®® - ä»…æ–‡æ¡£ç›¸å…³
            suggestions = [
                "Nginxé…ç½®",
                "æ•°æ®åº“ä¼˜åŒ–", 
                "ç›‘æ§å‘Šè­¦",
                "æ•…éšœæ’æŸ¥",
                "éƒ¨ç½²æ–‡æ¡£",
                "APIæ–‡æ¡£",
                "è¿ç»´æ‰‹å†Œ",
                "æŠ€æœ¯è§„èŒƒ"
            ]
        
        return {
            "query": q,
            "suggestions": suggestions[:10]  # æœ€å¤šè¿”å›10ä¸ªå»ºè®®
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æœç´¢å»ºè®®å¤±è´¥: {str(e)}")
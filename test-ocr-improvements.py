#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCRåŠŸèƒ½æ”¹è¿›æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•ä¸­æ–‡å­—ç¬¦é—´è·å’Œå®Œæ•´æ€§ä¼˜åŒ–æ•ˆæœ
"""
import os
import sys
import time
import logging
from pathlib import Path
from datetime import datetime

# æ·»åŠ backendè·¯å¾„åˆ°sys.path
backend_path = Path(__file__).parent / "backend"
sys.path.insert(0, str(backend_path))

from app.services.enhanced_content_extractor import EnhancedContentExtractor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('ocr_improvement_test.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

def analyze_text_quality(text: str, description: str = ""):
    """åˆ†ææ–‡æœ¬è´¨é‡"""
    if not text:
        return {"total_chars": 0, "quality": "æ— å†…å®¹"}
    
    analysis = {
        "description": description,
        "total_chars": len(text),
        "chinese_chars": len([c for c in text if '\u4e00' <= c <= '\u9fff']),
        "english_chars": len([c for c in text if c.isalpha() and ord(c) < 128]),
        "digit_chars": len([c for c in text if c.isdigit()]),
        "spaces": text.count(' '),
        "lines": len(text.split('\n'))
    }
    
    # æ£€æŸ¥å¸¸è§çš„é—´è·é—®é¢˜
    spacing_issues = []
    
    # æ£€æŸ¥ä¸­æ–‡å­—ç¬¦é—´çš„å¤šä½™ç©ºæ ¼
    import re
    chinese_with_spaces = re.findall(r'[\u4e00-\u9fff]\s+[\u4e00-\u9fff]', text)
    if chinese_with_spaces:
        spacing_issues.append(f"å‘ç°{len(chinese_with_spaces)}å¤„ä¸­æ–‡å­—ç¬¦é—´å¤šä½™ç©ºæ ¼")
        # æ˜¾ç¤ºå‰å‡ ä¸ªä¾‹å­
        examples = chinese_with_spaces[:3]
        spacing_issues.append(f"ç¤ºä¾‹: {', '.join(examples)}")
    
    # æ£€æŸ¥å¸¸è§çš„åˆ†ç¦»è¯æ±‡
    common_separated_words = ['ç½‘ ç»œ', 'å®‰ å…¨', 'æ•° æ®', 'ç³» ç»Ÿ', 'ä¿¡ æ¯', 'ç®¡ ç†', 'æŠ€ æœ¯']
    found_separated = [word for word in common_separated_words if word in text]
    if found_separated:
        spacing_issues.append(f"å‘ç°è¢«åˆ†ç¦»çš„å¸¸è§è¯æ±‡: {', '.join(found_separated)}")
    
    analysis["spacing_issues"] = spacing_issues
    
    # è´¨é‡è¯„çº§
    if analysis["total_chars"] == 0:
        quality_grade = "F - æ— å†…å®¹"
    elif len(spacing_issues) == 0:
        quality_grade = "A - ä¼˜ç§€"
    elif len(spacing_issues) <= 2:
        quality_grade = "B - è‰¯å¥½" 
    elif len(spacing_issues) <= 5:
        quality_grade = "C - ä¸€èˆ¬"
    else:
        quality_grade = "D - éœ€è¦æ”¹è¿›"
    
    analysis["quality_grade"] = quality_grade
    
    return analysis

def test_ocr_improvements(pdf_file_path: str):
    """æµ‹è¯•OCRæ”¹è¿›æ•ˆæœ"""
    print("=" * 60)
    print("OCRåŠŸèƒ½æ”¹è¿›æ•ˆæœæµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æµ‹è¯•æ–‡ä»¶: {pdf_file_path}")
    print()
    
    if not os.path.exists(pdf_file_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {pdf_file_path}")
        return False
    
    # åˆ›å»ºå¢å¼ºå†…å®¹æå–å™¨
    extractor = EnhancedContentExtractor()
    
    print("ğŸ” æ£€æŸ¥OCRç¯å¢ƒ...")
    print(f"OCRå¯ç”¨: {'âœ… æ˜¯' if extractor.has_ocr else 'âŒ å¦'}")
    
    if not extractor.has_ocr:
        print("âŒ OCRåŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·å…ˆè¿è¡Œ install-ocr-dependencies.bat")
        return False
    
    print()
    print("ğŸš€ å¼€å§‹OCRå¤„ç†æµ‹è¯•...")
    print("-" * 40)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # æå–å†…å®¹
    try:
        content, error = extractor.extract_content(pdf_file_path)
        processing_time = time.time() - start_time
        
        print(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        print()
        
        if error:
            print(f"âŒ æå–é”™è¯¯: {error}")
            return False
        
        if not content:
            print("âŒ æœªæå–åˆ°ä»»ä½•å†…å®¹")
            return False
        
        # åˆ†ææå–ç»“æœ
        print("ğŸ“Š å†…å®¹åˆ†æç»“æœ:")
        print("-" * 40)
        
        analysis = analyze_text_quality(content, "OCRä¼˜åŒ–å")
        
        print(f"æ€»å­—ç¬¦æ•°: {analysis['total_chars']:,}ä¸ª")
        print(f"ä¸­æ–‡å­—ç¬¦: {analysis['chinese_chars']:,}ä¸ª ({analysis['chinese_chars']/analysis['total_chars']*100:.1f}%)")
        print(f"è‹±æ–‡å­—ç¬¦: {analysis['english_chars']:,}ä¸ª ({analysis['english_chars']/analysis['total_chars']*100:.1f}%)")
        print(f"æ•°å­—å­—ç¬¦: {analysis['digit_chars']:,}ä¸ª ({analysis['digit_chars']/analysis['total_chars']*100:.1f}%)")
        print(f"ç©ºæ ¼æ•°é‡: {analysis['spaces']:,}ä¸ª")
        print(f"è¡Œæ•°: {analysis['lines']:,}è¡Œ")
        print(f"è´¨é‡è¯„çº§: {analysis['quality_grade']}")
        
        print()
        print("ğŸ” å­—ç¬¦é—´è·é—®é¢˜æ£€æŸ¥:")
        print("-" * 40)
        
        if analysis['spacing_issues']:
            for issue in analysis['spacing_issues']:
                print(f"âš ï¸ {issue}")
        else:
            print("âœ… æœªå‘ç°æ˜æ˜¾çš„å­—ç¬¦é—´è·é—®é¢˜")
        
        print()
        print("ğŸ“„ å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦):")
        print("-" * 40)
        preview = content[:500] + "..." if len(content) > 500 else content
        print(preview)
        
        print()
        print("ğŸ“‹ æ”¹è¿›æ•ˆæœæ€»ç»“:")
        print("-" * 40)
        
        improvements = []
        
        # åŸºäºåˆ†æç»“æœè¯„ä¼°æ”¹è¿›æ•ˆæœ
        if not analysis['spacing_issues']:
            improvements.append("âœ… ä¸­æ–‡å­—ç¬¦é—´è·å¤„ç†æ­£å¸¸")
        else:
            improvements.append(f"âš ï¸ ä»æœ‰{len(analysis['spacing_issues'])}ä¸ªé—´è·é—®é¢˜å¾…ä¼˜åŒ–")
        
        if analysis['chinese_chars'] > 0:
            improvements.append(f"âœ… ä¸­æ–‡è¯†åˆ«ç‡: {analysis['chinese_chars']/analysis['total_chars']*100:.1f}%")
        
        if analysis['total_chars'] >= 1000:
            improvements.append("âœ… å†…å®¹æå–å®Œæ•´æ€§è‰¯å¥½")
        elif analysis['total_chars'] >= 500:
            improvements.append("âš ï¸ å†…å®¹å¯èƒ½ä¸å¤Ÿå®Œæ•´")
        else:
            improvements.append("âŒ å†…å®¹æå–ä¸å®Œæ•´")
        
        for improvement in improvements:
            print(improvement)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        result_file = f"ocr_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(f"OCRæ”¹è¿›æµ‹è¯•ç»“æœ\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now()}\n")
            f.write(f"æµ‹è¯•æ–‡ä»¶: {pdf_file_path}\n")
            f.write(f"å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’\n\n")
            f.write("åˆ†æç»“æœ:\n")
            for key, value in analysis.items():
                if key != 'spacing_issues':
                    f.write(f"{key}: {value}\n")
            f.write("\né—´è·é—®é¢˜:\n")
            for issue in analysis['spacing_issues']:
                f.write(f"{issue}\n")
            f.write(f"\nå®Œæ•´å†…å®¹:\n{content}")
        
        print()
        print(f"ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        logger.exception("OCRæµ‹è¯•å¼‚å¸¸")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("OCRåŠŸèƒ½æ”¹è¿›æµ‹è¯•å·¥å…·")
    print("ç”¨äºéªŒè¯ä¸­æ–‡å­—ç¬¦é—´è·å’Œå®Œæ•´æ€§ä¼˜åŒ–æ•ˆæœ")
    print()
    
    # è·å–PDFæ–‡ä»¶è·¯å¾„
    if len(sys.argv) > 1:
        pdf_file = sys.argv[1]
    else:
        pdf_file = input("è¯·è¾“å…¥PDFæ–‡ä»¶è·¯å¾„: ").strip()
        if not pdf_file:
            print("æœªæä¾›æ–‡ä»¶è·¯å¾„ï¼Œé€€å‡ºæµ‹è¯•")
            return
    
    # æ‰§è¡Œæµ‹è¯•
    success = test_ocr_improvements(pdf_file)
    
    print()
    if success:
        print("âœ… OCRæ”¹è¿›æµ‹è¯•å®Œæˆ")
    else:
        print("âŒ OCRæ”¹è¿›æµ‹è¯•å¤±è´¥")
    
    print()
    input("æŒ‰ä»»æ„é”®é€€å‡º...")

if __name__ == "__main__":
    main()